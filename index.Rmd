---
title: "PM566 Final Project"
author: "Victoria Yin"
output: 
    html_document:
        toc: TRUE
        toc_float: TRUE
        code_folding: hide
---

This is my PM566 Final Project website.

<br>

# Introduction

Los Angeles County provides openly available data on all restaurant and market inspections over the past 5 years. Facilities are subject to inspection 1 to 3 times a year, and made public within 1 week of inspection date. The frequency in which restaurants and food markets are inspected depends on the public health risk associated with the food products served or prepared and on the facility's history of inspection grades. Inspectors deduct points based on violations and health risks, which is turned into a score out of 100. In addition, Los Angeles County data from 2018 on population health is publicly available. Demographic data, such as age and race distribution, socioeconomic data, such as proportion receiving EBT and proportion employed, and health outcomes data, such as proportion with asthma and rates of suicide, are provided for 87 cities within Los Angeles County.

## Objective

I am interested in exploring restaurant inspection ratings in LA County. I have a few questions, with the main one being: Are restaurant inspection ratings associated with community health status? 
Secondary questions include:
What are the "safest" and most "dangerous" cities in LA County for eating restaurant food? What restaurant chain is the "safest" to eat at? What restaurant chains should one proceed with caution?

# Methods
## Reading in and wrangling the data

I used 2 data sets which I merged together for this project. Both are available at data.lacounty.gov to download as CSV (I have also uploaded these datasets to my github repository). The first is a dataset of all LA County restaurant inspections. I added LA County city health data to see if there were any relationships between public health outcomes and local restaurant hygiene. These datasets were merged by city name, and no restaurant was missing its city in the first dataset. City names were briefly inspected to ensure matching would be feasible. As Los Angeles had many sub-cities for which there was health data, I only included the "City of Los Angeles" data to represent the local public health for any restaurant with city listed as Los Angeles. Only restaurants in cities with health data were included in this analysis. 

## Data Exploration

Data were explored utilizing R package ggplot2 to create a histogram of scores. Implausibly low scores were deleted (score less than 50, of which there was 1 value with score 3). Average scores within cities were computed and compared. Restaurant chains were identified through tokenizing words as bigrams, and looking to see most common chain restaurants. The following set of 9 chains were selected: McDonald's, Jack in the Box, Starbucks, El Pollo Loco, Panda Express, Taco Bell, Del Taco, In N Out, Panera Bread. Average chain inspection scores were computed and compared. Measures of public health were selected: proportion with depression, proportion with obesity, proportion with diabetes.

To observe the relationship between restaurant rating and community health status, only chain restaurants were analyzed (due to sample size). Chain restaurant addresses were geocoded using tidygeocoder and OpenStreetMaps in order to map latitudes and longitudes on the plots. This method does not require an API key!

```{r setup, message=FALSE, echo=FALSE, warning=FALSE}
# Initialize code chunk options
if(!require(data.table)) install.packages("data.table")
library(data.table)
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
if(!require(tidytext)) install.packages("tidytext")
library(tidytext)
if(!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)
if(!require(dtplyr)) install.packages("dtplyr")
library(dtplyr)
if(!require(knitr)) install.packages("knitr")
library(knitr)
options(digits=2)
if(!require(forcats)) install.packages("forcats")
library(forcats)
if(!require(utils)) install.packages("utils")
library(utils)
if(!require(downloader)) install.packages("downloader")
library(downloader)
if(!require(ggmap)) install.packages("ggmap")
library(ggmap)
if(!require(leaflet)) install.packages("leaflet")
library(leaflet)
if(!require(leaflet.extras)) install.packages("leaflet.extras")
library(leaflet.extras)
if(!require(plotly)) install.packages("plotly")
library(plotly)

opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  eval=TRUE,
  echo = TRUE,
  cache = FALSE,
  fig.width = 7, 
  fig.align = 'center',
  fig.asp = 0.618,
  out.width = "700px")

# Read in and clean data
if (!file.exists("LACinspections.csv.zip"))
  download(
    url = "https://github.com/v-yin/PM566-Midterm/blob/main/LACinspections.csv.zip?raw=true",
    dest = "LACinspections.csv.zip",
    mode="wb"
    )
unzip("LACinspections.csv.zip", exdir="./")
inspect <- read.csv("LACinspections.csv")

if (!file.exists("LAChealth.csv"))
  download(
    url = "https://raw.githubusercontent.com/v-yin/PM566-Midterm/main/LAChealth.csv",
    dest = "LAChealth.csv",
    mode="wb"
    )
health <- read.csv("LAChealth.csv")

health$GEONAME <- toupper(health$GEONAME)
health$GEONAME <- replace(health$GEONAME, health$GEONAME=="LOS ANGELES, CITY OF", "LOS ANGELES")

resthealth <- merge(
  x = inspect,
  y = health,
  by.x = "FACILITY_CITY",
  by.y = "GEONAME",
  all.x = FALSE,
  all.y = FALSE
)
resthealth <- data.table(resthealth)

# Delete scores less than 50
library(data.table)
resthealth <- resthealth[SCORE>50]
# Find restaurant chains
# resthealth %>% unnest_ngrams(word, FACILITY_NAME, n=2) %>% anti_join(stop_words, by = c("word")) # %>% count(word, sort=TRUE) %>% as_tibble() %>% print(n=100)
# Create chain variable
resthealth$FACILITY_NAME <- toupper(resthealth$FACILITY_NAME)
resthealth$CHAIN <- ifelse(grepl("MCDONALD", resthealth$FACILITY_NAME), "McDonald's", ifelse(grepl("JACK IN THE BOX", resthealth$FACILITY_NAME), "Jack in the Box", ifelse(grepl("STARBUCKS", resthealth$FACILITY_NAME), "Starbucks", ifelse(grepl("EL POLLO LOCO", resthealth$FACILITY_NAME), "El Pollo Loco", ifelse(grepl("PANDA EXPRESS", resthealth$FACILITY_NAME), "Panda Express", ifelse(grepl("TACO BELL", resthealth$FACILITY_NAME), "Taco Bell", ifelse(grepl("DEL TACO", resthealth$FACILITY_NAME), "Del Taco", ifelse(grepl("OUT BURGER", resthealth$FACILITY_NAME), "In N Out", ifelse(grepl("PANERA BREAD", resthealth$FACILITY_NAME), "Panera Bread", NA)))))))))
# Find average inspection score by chain
chain_avg <- resthealth[ , .(
  scoreavg = mean(SCORE) 
), by = "CHAIN"]
# Clean health outcome data to be numeric
resthealth$Prop_obse <- as.numeric(as.character(resthealth$Prop_obse))
resthealth$Prop_DM <- as.numeric(as.character(resthealth$Prop_DM))

library(tidygeocoder)

resthealth$fulladdress <- paste0(resthealth$FACILITY_ADDRESS, ", ", resthealth$FACILITY_CITY, ", CA ", resthealth$FACILITY_ZIP)

# restrict to chains only (too many data points to geocode)
# chains <- resthealth[!is.na(CHAIN)]
# chains <- as.data.frame(chains)

# chains <- chains %>% tidygeocoder::geocode(fulladdress, method = 'osm', lat = latitude , long = longitude)

# Take data set from github

if (!file.exists("chains.csv"))
  download(
    url = "https://github.com/v-yin/PM566-FinalProject/blob/main/chains.csv?raw=true",
    dest = "chains.csv",
    mode="wb"
    )
chains <- read.csv("chains.csv")
chains <- as.data.table(chains)
```

```{r initial data exploration, echo=FALSE, results = 'hide', message=FALSE}
library(ggplot2)
scorehisto <- ggplot(resthealth, aes(x=SCORE)) +
  geom_bar(fill="red") +
  ggtitle("Distribution of LA County Restaurant Inspection Scores, 2017-2022") +
  xlab("Inspection Score")


citysum <- resthealth %>% group_by(FACILITY_CITY) %>% summarise(mean_score = mean(SCORE), sd_fev = sd(SCORE), ninspect = n_distinct(RECORD_ID), Prop_DM, Prop_obse, Prop_depr) %>% distinct() 


```

In total, there were `r nrow(resthealth)` inspections of `r n_distinct(resthealth$FACILITY_ID)` restaurants in `r n_distinct(resthealth$FACILITY_CITY)` cities within LA County.

Of the `r nrow(resthealth)` inspections included in the analysis, the average grade was `r mean(resthealth$SCORE)` with a standard deviation of `r sd(resthealth$SCORE)`. The highest score was a perfect score, `r max(resthealth$SCORE)` whereas the lowest score was `r min(resthealth$SCORE)`. Interestingly, there appears to be a peak at 90, which corresponds to the lowest possible score to achieve an A rating. This may hint at bias involved in the inspection grading process.
```{r histogram}
scorehisto

citysum %>% arrange(desc(mean_score)) %>% slice(1:5) %>%  knitr::kable(col.names = c("City", "Average Score", "Standard Deviation of Score", "Number of Inspections in City", "Proportion Diabetes", "Proportion Obesity", "Proportion Depression"), caption = "Top 5 Cities") 

citysum %>% arrange(mean_score) %>% slice(1:5) %>% knitr::kable(col.names = c("City", "Average Score", "Standard Deviation of Score", "Number of Inspections in City", "Proportion Diabetes", "Proportion Obesity", "Proportion Depression"), caption = "Bottom 5 Cities")

```



